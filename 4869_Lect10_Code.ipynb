{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ITP4869\n",
    "## Lecture 10 (RDD Programming) - Code Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://Johnny-Probook:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Start</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=Start>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext(appName='Start')\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spark', 'rdd', 'python']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = sc.parallelize(['spark', 'rdd', 'python'])\n",
    "lines.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hadoop'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sc.textFile('data.txt')\n",
    "words = data.flatMap(lambda line: line.split(' '))\n",
    "words.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDD Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hadoop is an elegant fellow.', 'An elephant gentle and mellow.', 'He never gets mad,', 'Or does anything bad,', 'Because, at his core, he is yellow.']\n",
      "[28, 30, 18, 21, 35]\n",
      "Total length is 132\n"
     ]
    }
   ],
   "source": [
    "lines = sc.textFile(\"data.txt\")\n",
    "lineLengths = lines.map(lambda s: len(s))\n",
    "totalLength = lineLengths.reduce(lambda a, b: a + b)\n",
    "print(lines.collect())\n",
    "print(lineLengths.collect())\n",
    "print('Total length is', totalLength)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 5, 6, 7]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize(range(1,6))\n",
    "result = rdd.map(lambda x: x+2)\n",
    "result.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hadoop',\n",
       " 'is',\n",
       " 'an',\n",
       " 'elegant',\n",
       " 'fellow.',\n",
       " 'An',\n",
       " 'elephant',\n",
       " 'gentle',\n",
       " 'and',\n",
       " 'mellow.',\n",
       " 'He',\n",
       " 'never',\n",
       " 'gets',\n",
       " 'mad,',\n",
       " 'Or',\n",
       " 'does',\n",
       " 'anything',\n",
       " 'bad,',\n",
       " 'Because,',\n",
       " 'at',\n",
       " 'his',\n",
       " 'core,',\n",
       " 'he',\n",
       " 'is',\n",
       " 'yellow.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.textFile(\"data.txt\")\n",
    "lines = rdd.flatMap(lambda lines: lines.split(' '))\n",
    "lines.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Hadoop', 'is', 'an', 'elegant', 'fellow.'],\n",
       " ['An', 'elephant', 'gentle', 'and', 'mellow.'],\n",
       " ['He', 'never', 'gets', 'mad,'],\n",
       " ['Or', 'does', 'anything', 'bad,'],\n",
       " ['Because,', 'at', 'his', 'core,', 'he', 'is', 'yellow.']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.textFile(\"data.txt\")\n",
    "lines = rdd.map(lambda lines: lines.split(' '))\n",
    "lines.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 6, 8, 10]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize(range(1,11))\n",
    "filtered_nums = rdd.filter(lambda n: n%2 == 0)\n",
    "filtered_nums.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Spark', 'Spark', 'Hadoop', 'Flink', 'Big data', 'Spark', 'Flink']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1 = sc.parallelize(['Spark', 'Spark', 'Hadoop', 'Flink'])\n",
    "rdd2 = sc.parallelize(['Big data', 'Spark', 'Flink'])\n",
    "rdd3 = rdd1.union(rdd2)\n",
    "rdd3.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Flink', 'Spark']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1 = sc.parallelize(['Spark', 'Spark', 'Hadoop', 'Flink'])\n",
    "rdd2 = sc.parallelize(['Big data', 'Spark', 'Flink'])\n",
    "rdd3 = rdd1.intersection(rdd2)\n",
    "rdd3.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hadoop', 'Spark', 'Flink']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1 = sc.parallelize(['Spark', 'Spark', 'Hadoop', 'Flink'])\n",
    "rdd1.distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('b', (2, 7)), ('c', (3, 3)), ('c', (3, 8)), ('a', (1, 4)), ('a', (1, 6))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1 = sc.parallelize([('a',1),('b',2),('c',3)])\n",
    "rdd2 = sc.parallelize([('a',4),('a',6),('b',7),('c',3),('c',8)])\n",
    "rdd1.join(rdd2).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize([1, 2, 2, 3, 4, 5, 5, 6])\n",
    "print(rdd.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize([1, 2, 2, 3, 4, 5, 5, 6])\n",
    "print(rdd.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize(range(10))\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('k', 5), ('s', 3), ('s', 4)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize([('k',5),('s',3),('s',4),('p',7),\n",
    "('p',5),('t',8),('k',6)])\n",
    "rdd.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('t', 8), ('s', 4), ('s', 3)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize([('k',5),('s',3),('s',4),('p',7),\n",
    "('p',5),('t',8),('k',6)])\n",
    "rdd.top(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {1: 1, 2: 2, 3: 1, 4: 1, 5: 2, 6: 1})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize([1, 2, 2, 3, 4, 5, 5, 6])\n",
    "rdd.countByValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize([20,32,45,62,8,5])\n",
    "rdd.reduce(lambda n1,n2: n1+n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize([1,2,3,4,5])\n",
    "identity = 0  # 0 for sum, 1 for multiplication\n",
    "sum = rdd.fold(identity, lambda t1,t2: t1+t2)\n",
    "sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 2, 3, 4, 5], 15)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqOp = lambda data, item: (data[0] + [item], data[1] + item)\n",
    "combOp = lambda d1, d2: (d1[0] + d2[0], d1[1] + d2[1])\n",
    "rdd = sc.parallelize([1,2,3,4,5])\n",
    "agg = rdd.aggregate(([], 0), seqOp, combOp)\n",
    "agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "names = []\n",
    "prices = []\n",
    "nb_in_stock = []\n",
    "img_urls = []\n",
    "categories = []\n",
    "ratings = []\n",
    "\n",
    "# Scrape data for every book URL\n",
    "for url in booksURLs:\n",
    "    soup = getAndParseURL(url)\n",
    "    names.append(soup.find(\"div\", class_ = re.compile(\"product_main\"))\\\n",
    "                 .h1.text)\n",
    "    # Get rid of the pound sign\n",
    "    prices.append(soup.find(\"p\", class_ = \"price_color\").text[2:])\n",
    "    # Number of available products (Get rid of non numerical characters)\n",
    "    nb_in_stock.append(re.sub(\"[^0-9]\", \"\", \\\n",
    "                    soup.find(\"p\", class_ = \"instock availability\").text))\n",
    "    img_urls.append(url.replace(\"index.html\", \"\") + soup.find(\"img\").get(\"src\"))\n",
    "    categories.append(soup.find(\"a\", href = re.compile(\"../category/books/\"))\\\n",
    "                      .get(\"href\").split(\"/\")[3])\n",
    "    ratings.append(soup.find(\"p\", class_ = re.compile(\"star-rating\"))\\\n",
    "                   .get(\"class\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add data into a DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "scraped_data = pd.DataFrame({'name': names, 'price': prices, \\\n",
    "                             'nb_in_stock': nb_in_stock, \"url_img\": img_urls, \\\n",
    "                             \"product_category\": categories, \"rating\": ratings})\n",
    "scraped_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accumulator<id=0, value=0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accum = sc.accumulator(0)\n",
    "accum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.parallelize([1, 2, 3, 4]).foreach(lambda x: accum.add(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accum.value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
